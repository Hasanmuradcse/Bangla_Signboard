{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9db8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cab04116",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from datasets import load_dataset\n",
    "import  numpy as np\n",
    "f=open(r\"C:\\Users\\Administrator\\Desktop\\my research(Shakib)\\error correction model/Bangla Bornomala datasetv4.txt\",\"r\",encoding=\"utf-8\").read().split(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8de08a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def space_removed(ch):\n",
    "  ch=[x for x in ch if x!=' ']\n",
    "  return ''.join(ch)\n",
    "def cleaning(st):\n",
    "  st=[space_removed(x) for x in st.split(\",\") if len(x)!=0]\n",
    "  return st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b2294017",
   "metadata": {},
   "outputs": [],
   "source": [
    "character={}\n",
    "for x in f:\n",
    "  main=space_removed(x.split(\"-->\")[0])\n",
    "  arr=[]\n",
    "  for i,x2 in enumerate(x.split(\"\\n\")):\n",
    "    if i==0 and len(x2.split(\"-->\"))>=3:\n",
    "      xx=x2.split(\"-->\")[2]  \n",
    "      arr.append(xx)\n",
    "    elif len(x2.split(\"-->\"))>=2:\n",
    "      xx=x2.split(\"-->\")[1]\n",
    "      arr.append(xx)\n",
    "  if len(arr)>=3:\n",
    "    character[main]={\"1st order\":cleaning(arr[0]),\"2nd order\":cleaning(arr[1]),\"other\":cleaning(arr[2]) }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b7175d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_char=[x for x in character]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ad9db2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def arange(w,dis):\n",
    "  word,_dis=[],[]\n",
    "  for x in dis:\n",
    "    word.append(x)\n",
    "    _dis.append(dis[x])\n",
    "  return {\"word\":word,\"prob\":_dis}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8b917f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob=.8\n",
    "first_order={}\n",
    "order=\"1st order\"\n",
    "for x in character:\n",
    "  dis={}\n",
    "  if len(character[x][order])>=4:\n",
    "    per_prob=prob/4.0;\n",
    "    cnt=0\n",
    "    for x2 in character[x][order]:\n",
    "      dis[x2]=per_prob\n",
    "      cnt+=1\n",
    "      if cnt==4:\n",
    "        break\n",
    "  elif len(character[x][order])==3:\n",
    "    cnt=0\n",
    "    per_prob=.4\n",
    "    for x2 in character[x][order]:\n",
    "      dis[x2]=per_prob\n",
    "      cnt+=1\n",
    "      if cnt==2:\n",
    "        break\n",
    "  else:\n",
    "    per_prob=prob/len(character[x][order])\n",
    "    for x2 in character[x][order]:\n",
    "      dis[x2]=per_prob\n",
    "      cnt+=1\n",
    "  first_order[x]=arange(x,dis)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a40dfac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob=.15\n",
    "second_order={}\n",
    "order=\"2nd order\"\n",
    "for x in character:\n",
    "  dis={}\n",
    "  if len(character[x][order])>=3:\n",
    "    per_prob=.05\n",
    "    cnt=0\n",
    "    for x2 in character[x][order]:\n",
    "      dis[x2]=per_prob\n",
    "      cnt+=1\n",
    "      if cnt==3:\n",
    "        break\n",
    "  else:  \n",
    "    per_prob=prob/len(character[x][order])\n",
    "    for x2 in character[x][order]:\n",
    "      dis[x2]=per_prob\n",
    "  second_order[x]=arange(x,dis)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e897933b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prob=.05\n",
    "other={}\n",
    "order=\"other\"\n",
    "for x in character:\n",
    "  dis={}\n",
    "  if len(character[x][order])>=2:\n",
    "    per_prob=.025\n",
    "    cnt=0\n",
    "    for x2 in character[x][order]:\n",
    "      dis[x2]=per_prob\n",
    "      cnt+=1\n",
    "      if cnt==2:\n",
    "        break\n",
    "  else:  \n",
    "    per_prob=prob/len(character[x][order])\n",
    "    for x2 in character[x][order]:\n",
    "      dis[x2]=per_prob\n",
    "  other[x]=arange(x,dis)  \n",
    "# other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b5d9fc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_prob_dis={}\n",
    "for x in first_order:\n",
    "  word=[]\n",
    "  prob=[]\n",
    "  word.extend(first_order[x]['word'])\n",
    "  word.extend(second_order[x]['word'])\n",
    "  word.extend(other[x]['word'])\n",
    "  prob.extend(first_order[x]['prob'])\n",
    "  prob.extend(second_order[x]['prob'])\n",
    "  prob.extend(other[x]['prob'])\n",
    "  char_prob_dis[x]={\"word\":word,\"prob\":prob}\n",
    "# char_prob_dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "88f2623a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ক': {'word': ['ল', 'ম', 'জ', 'য', 'উ', 'ঊ', 'ু', 'খ', '্'],\n",
       "  'prob': [0.2, 0.2, 0.2, 0.2, 0.05, 0.05, 0.05, 0.025, 0.025]},\n",
       " 'খ': {'word': ['ক', 'ল', 'ম', 'জ', 'উ', 'ঊ', 'ু', 'কোঁ', 'কপ'],\n",
       "  'prob': [0.2, 0.2, 0.2, 0.2, 0.05, 0.05, 0.05, 0.025, 0.025]},\n",
       " 'গ': {'word': ['হ', 'ব', 'ভ', 'ভঁ', 'র', 'ঢ়', 'ড়', 'ই', 'ঈ'],\n",
       "  'prob': [0.2, 0.2, 0.2, 0.2, 0.05, 0.05, 0.05, 0.025, 0.025]},\n",
       " 'ঘ': {'word': ['হ', 'ব', 'ভ', 'ভঁ', 'গক', 'গি', 'গী', 'ও', 'য়'],\n",
       "  'prob': [0.2, 0.2, 0.2, 0.2, 0.05, 0.05, 0.05, 0.025, 0.025]},\n",
       " 'ঙ': {'word': ['ং', 'ঞ', 'ঙ্গ', 'নগ', '', 'ক', 'ই', 'ণে', 'ঙে'],\n",
       "  'prob': [0.2, 0.2, 0.2, 0.2, 0.05, 0.05, 0.05, 0.025, 0.025]},\n",
       " 'চ': {'word': ['ছ', 'ভ', 'ভঁ', 'এক্স', 'ব', 'গ', 'ত', 'ল', 'ম'],\n",
       "  'prob': [0.2, 0.2, 0.2, 0.2, 0.05, 0.05, 0.05, 0.025, 0.025]},\n",
       " 'ছ': {'word': ['চ', 'চছ', 'ভ', 'ভঁ', 'ব', 'গ', 'ত', 'ল', 'ম'],\n",
       "  'prob': [0.2, 0.2, 0.2, 0.2, 0.05, 0.05, 0.05, 0.025, 0.025]},\n",
       " 'জ': {'word': ['য', 'ক', 'ম', 'ন', '', 'ল', 'ও', ';', 'ঃ'],\n",
       "  'prob': [0.2, 0.2, 0.2, 0.2, 0.05, 0.05, 0.05, 0.025, 0.025]},\n",
       " 'ঝ': {'word': ['যঝ', 'য', 'জ', 'হ', 'জক', 'যক', 'জি', 'ল', 'ম'],\n",
       "  'prob': [0.2, 0.2, 0.2, 0.2, 0.05, 0.05, 0.05, 0.025, 0.025]},\n",
       " 'ঞ': {'word': ['ণঞ', 'ণঙ', 'ণনগ', 'ণঙ্গ', 'গ', 'কগ', 'ইগ', 'ল', 'ম'],\n",
       "  'prob': [0.2, 0.2, 0.2, 0.2, 0.05, 0.05, 0.05, 0.025, 0.025]},\n",
       " 'ট': {'word': ['ত', 'তঁ', 'ৎ', 'টি', 'ইউ', 'উ', 'ঊ', 'ল', 'ম'],\n",
       "  'prob': [0.2, 0.2, 0.2, 0.2, 0.05, 0.05, 0.05, 0.025, 0.025]},\n",
       " 'ঠ': {'word': ['থ', 'টিএইচ', 'ত্য', 'তয়', 'ত্ম', 'তম', 'টম', 'ল', 'ম'],\n",
       "  'prob': [0.2, 0.2, 0.2, 0.2, 0.05, 0.05, 0.05, 0.025, 0.025]},\n",
       " 'ড': {'word': ['দ', 'দঃ', 'ডঃ', 'চ', 'ভঁ', 'ভ', 'গ', 'ল', 'ম'],\n",
       "  'prob': [0.2, 0.2, 0.2, 0.2, 0.05, 0.05, 0.05, 0.025, 0.025]},\n",
       " 'ঢ': {'word': ['ধ', 'দহ', 'ডঃ', 'দঃ', 'জঝ', 'ঝ', 'যহ', 'ল', 'ম'],\n",
       "  'prob': [0.2, 0.2, 0.2, 0.2, 0.05, 0.05, 0.05, 0.025, 0.025]},\n",
       " 'ণ': {'word': ['ন', 'ঙ', 'ঞ', 'ম', 'ক', 'ই', 'ঈ', 'ল', 'ও'],\n",
       "  'prob': [0.2, 0.2, 0.2, 0.2, 0.05, 0.05, 0.05, 0.025, 0.025]},\n",
       " 'ত': {'word': ['ট', 'তঁ', 'ৎ', '৬', 'উ', 'ঊ', 'ু', 'ল', 'ম'],\n",
       "  'prob': [0.2, 0.2, 0.2, 0.2, 0.05, 0.05, 0.05, 0.025, 0.025]},\n",
       " 'থ': {'word': ['ঠ', 'ত্য', 'তয়', 'তঁয়', 'ত্ম', 'তম', 'টম', 'ল', 'ম'],\n",
       "  'prob': [0.2, 0.2, 0.2, 0.2, 0.05, 0.05, 0.05, 0.025, 0.025]},\n",
       " 'দ': {'word': ['ড', 'দঃ', 'ডঃ', 'চ', 'ভঁ', 'ভ', 'গ', 'ল', 'ম'],\n",
       "  'prob': [0.2, 0.2, 0.2, 0.2, 0.05, 0.05, 0.05, 0.025, 0.025]},\n",
       " 'ধ': {'word': ['ঢ', 'দহ', 'ডঃ', 'দঃ', 'জঝ', 'ঝ', 'যহ', 'ল', 'ম'],\n",
       "  'prob': [0.2, 0.2, 0.2, 0.2, 0.05, 0.05, 0.05, 0.025, 0.025]},\n",
       " 'ন': {'word': ['ণ', 'ঙ', 'ঞ', 'ম', 'ক', 'ই', 'ঈ', 'ল', 'ও'],\n",
       "  'prob': [0.2, 0.2, 0.2, 0.2, 0.05, 0.05, 0.05, 0.025, 0.025]},\n",
       " 'প': {'word': ['[', '০', 'ও', 'য়', ']', '=', \"'\", 'ঠ', 'থ'],\n",
       "  'prob': [0.2, 0.2, 0.2, 0.2, 0.05, 0.05, 0.05, 0.025, 0.025]},\n",
       " 'ফ': {'word': ['পফ', 'ভ', 'ভঁ', 'গ', 'ব', 'হ', 'ইয়', 'ঠ', 'থ'],\n",
       "  'prob': [0.2, 0.2, 0.2, 0.2, 0.05, 0.05, 0.05, 0.025, 0.025]},\n",
       " 'ব': {'word': ['ন', 'ণ', 'ঙ', 'ঞ', 'ম', 'জ', 'য', 'ঠ', 'থ'],\n",
       "  'prob': [0.2, 0.2, 0.2, 0.2, 0.05, 0.05, 0.05, 0.025, 0.025]},\n",
       " 'ভ': {'word': ['ভঁ', 'বহ', 'ব', 'গ', 'ন', 'ণ', 'ঙ', 'ঘ', 'ঠ'],\n",
       "  'prob': [0.2, 0.2, 0.2, 0.2, 0.05, 0.05, 0.05, 0.025, 0.025]},\n",
       " 'ম': {'word': ['ক', 'য', 'জ', 'ন', '।', 'ল', 'ও', 'ঘ', 'ঠ'],\n",
       "  'prob': [0.2, 0.2, 0.2, 0.2, 0.05, 0.05, 0.05, 0.025, 0.025]},\n",
       " 'স': {'word': ['সঃ', 'শ', 'ষ', 'এক্স', 'ছ', 'চ', 'ফ', 'ঘ', 'ঠ'],\n",
       "  'prob': [0.2, 0.2, 0.2, 0.2, 0.05, 0.05, 0.05, 0.025, 0.025]},\n",
       " 'হ': {'word': ['জ', 'য', 'ন', 'ণ', 'ম', 'ক', 'ই', 'ঠ', 'থ'],\n",
       "  'prob': [0.2, 0.2, 0.2, 0.2, 0.05, 0.05, 0.05, 0.025, 0.025]},\n",
       " 'ড়': {'word': ['র', 'ঢ়', 'টি', 'ত', 'ডব্লিউ', 'ওঁ', 'ওঃ', 'ল', 'ম'],\n",
       "  'prob': [0.2, 0.2, 0.2, 0.2, 0.05, 0.05, 0.05, 0.025, 0.025]},\n",
       " 'ঢ়': {'word': ['র', 'ড়', 'রহ', 'রহঃ', 'রট', 'রত', 'ড়ত', 'ল', 'ম'],\n",
       "  'prob': [0.2, 0.2, 0.2, 0.2, 0.05, 0.05, 0.05, 0.025, 0.025]},\n",
       " 'আ': {'word': ['ক', 'স', 'ও', 'দ', 'এক্স', 'এ', 'ফ'],\n",
       "  'prob': [0.4, 0.4, 0.05, 0.05, 0.05, 0.025, 0.025]},\n",
       " 'অ': {'word': ['৯', 'প', 'ল', 'ই', 'উ', 'জ', 'ম', 'ইয়', 'হ'],\n",
       "  'prob': [0.2, 0.2, 0.2, 0.2, 0.05, 0.05, 0.05, 0.025, 0.025]},\n",
       " 'ই': {'word': ['৮', '৯', 'অ', 'ক', 'প', 'ল', 'ইয়', 'ত', 'হ'],\n",
       "  'prob': [0.2, 0.2, 0.2, 0.2, 0.05, 0.05, 0.05, 0.025, 0.025]},\n",
       " 'ঈ': {'word': ['ও', 'ক', 'জ', 'ঊ', 'প', 'ল', 'হ', 'ম', 'ট'],\n",
       "  'prob': [0.2, 0.2, 0.2, 0.2, 0.05, 0.05, 0.05, 0.025, 0.025]},\n",
       " 'উ': {'word': ['ই', '৮', '৭', 'ইয়', 'অ', 'ক', 'ম', 'প', 'ল'],\n",
       "  'prob': [0.2, 0.2, 0.2, 0.2, 0.05, 0.05, 0.05, 0.025, 0.025]},\n",
       " 'ঊ': {'word': ['য়', 'জ', 'ঈ', '&', 'ও', 'ক', 'ম', 'প', 'ল'],\n",
       "  'prob': [0.2, 0.2, 0.2, 0.2, 0.05, 0.05, 0.05, 0.025, 0.025]},\n",
       " 'ঋ': {'word': ['রর', 'র্ক', 'ররু', 'র্জ', 'র্প', 'র্ল', 'র্ম', 'র্ত', 'র্ন'],\n",
       "  'prob': [0.2, 0.2, 0.2, 0.2, 0.05, 0.05, 0.05, 0.025, 0.025]},\n",
       " 'এ': {'word': ['র', 'দ', 'স', 'ও', 'ত', 'ফ', 'চ', 'ইয়', 'গ'],\n",
       "  'prob': [0.2, 0.2, 0.2, 0.2, 0.05, 0.05, 0.05, 0.025, 0.025]},\n",
       " 'ঐ': {'word': ['ও৮', 'ও৯', 'ওও', 'ওক', 'ওপ', 'ওল', 'ওম', 'ওণ', 'ওহ'],\n",
       "  'prob': [0.2, 0.2, 0.2, 0.2, 0.05, 0.05, 0.05, 0.025, 0.025]},\n",
       " 'ও': {'word': ['প', 'ল', 'ঈ', 'ক', '[', 'ঊ', 'জ', 'ক', 'ও'],\n",
       "  'prob': [0.2, 0.2, 0.2, 0.2, 0.05, 0.05, 0.05, 0.025, 0.025]},\n",
       " 'ঔ': {'word': ['ও৭', 'ও৮', 'ঐ', 'ওজ', 'ওও', 'ওক', 'ওণ', 'ওপ', 'ওল'],\n",
       "  'prob': [0.2, 0.2, 0.2, 0.2, 0.05, 0.05, 0.05, 0.025, 0.025]},\n",
       " 'য': {'word': ['আ', 'এক্স', 'ক', 'ও', 'দ', 'এ', 'ফ'],\n",
       "  'prob': [0.4, 0.4, 0.05, 0.05, 0.05, 0.025, 0.025]},\n",
       " 'র': {'word': ['ফ', 'ত', 'এ', '৫', 'ইয়', 'গ', 'ভ', 'ক', 'আ'],\n",
       "  'prob': [0.2, 0.2, 0.2, 0.2, 0.05, 0.05, 0.05, 0.025, 0.025]},\n",
       " 'ল': {'word': ['অ', 'ক', 'প', ';', '‘', '[', '/', ']', '\\\\'],\n",
       "  'prob': [0.2, 0.2, 0.2, 0.2, 0.05, 0.05, 0.05, 0.025, 0.025]},\n",
       " 'শ': {'word': ['আ', 'ও', 'ড', 'এক্স', 'ক', 'এ', 'ফ', 'ড়', 'গ'],\n",
       "  'prob': [0.2, 0.2, 0.2, 0.2, 0.05, 0.05, 0.05, 0.025, 0.025]},\n",
       " 'ষ': {'word': ['শ্য', 'শজ', 'শ্ন', 'শব', 'শু', 'শক', 'শ্ম', 'শ্ল', 'শক'],\n",
       "  'prob': [0.2, 0.2, 0.2, 0.2, 0.05, 0.05, 0.05, 0.025, 0.025]},\n",
       " 'য়': {'word': ['৭', '৬', 'ঊ', 'হ', 'ঈ', 'জ', 'ব', 'ও', 'ক'],\n",
       "  'prob': [0.2, 0.2, 0.2, 0.2, 0.05, 0.05, 0.05, 0.025, 0.025]},\n",
       " 'ৎ': {'word': ['ত১১', 'ত২২', 'তকক', 'তী', 'তসস'],\n",
       "  'prob': [0.8, 0.075, 0.075, 0.025, 0.025]},\n",
       " 'ং': {'word': ['নহ', 'নব', 'নভ', 'নফ', 'ন্য', 'ঞ্জ', 'ন্ন', 'নে', 'ন্স'],\n",
       "  'prob': [0.2, 0.2, 0.2, 0.2, 0.05, 0.05, 0.05, 0.025, 0.025]},\n",
       " 'ঃ': {'word': ['প', '”', '?', '>', '.', '}', 'ও', 'ঈ', 'জ'],\n",
       "  'prob': [0.2, 0.2, 0.2, 0.2, 0.05, 0.05, 0.05, 0.025, 0.025]},\n",
       " 'ঁ': {'word': ['&', '%', 'য়', 'ট', '*', 'ঊ', 'হ', 'প', 'ল'],\n",
       "  'prob': [0.2, 0.2, 0.2, 0.2, 0.05, 0.05, 0.05, 0.025, 0.025]},\n",
       " 'া': {'word': ['্ব', '্য', 'ক', 'স', 'ও', 'দ', 'এক্স', 'ি', 'ী'],\n",
       "  'prob': [0.2, 0.2, 0.2, 0.2, 0.05, 0.05, 0.05, 0.025, 0.025]},\n",
       " 'ি': {'word': ['ু', '্য', '৮', '৯', 'প', 'ল', 'ইয়', 'া', 'ী'],\n",
       "  'prob': [0.2, 0.2, 0.2, 0.2, 0.05, 0.05, 0.05, 0.025, 0.025]},\n",
       " 'ী': {'word': ['ূ', '্য', 'ও', 'ক', 'প', 'ল', 'হ', 'া', 'ি'],\n",
       "  'prob': [0.2, 0.2, 0.2, 0.2, 0.05, 0.05, 0.05, 0.025, 0.025]},\n",
       " 'ু': {'word': ['ী', '্য', 'ই', '৮', 'অ', 'ক', 'ম', 'া', 'ি'],\n",
       "  'prob': [0.2, 0.2, 0.2, 0.2, 0.05, 0.05, 0.05, 0.025, 0.025]},\n",
       " 'ূ': {'word': ['ী', '্য', 'য়', 'জ', 'ও', 'ক', 'ম', 'া', 'ি'],\n",
       "  'prob': [0.2, 0.2, 0.2, 0.2, 0.05, 0.05, 0.05, 0.025, 0.025]},\n",
       " 'ৃ': {'word': ['রর', 'র্ক', 'ররু', 'র্জ', 'র্প', 'র্ল', 'র্ম', 'া', 'ি'],\n",
       "  'prob': [0.2, 0.2, 0.2, 0.2, 0.05, 0.05, 0.05, 0.025, 0.025]},\n",
       " 'ে': {'word': ['্র', 'র', 'দ', 'স', 'ত', 'ফ', 'চ', 'া', 'ি'],\n",
       "  'prob': [0.2, 0.2, 0.2, 0.2, 0.05, 0.05, 0.05, 0.025, 0.025]},\n",
       " 'ৈ': {'word': ['ৌ', 'ও৮', 'ও৯', 'ওও', 'ওপ', 'ওল', 'ওম', 'া', 'ি'],\n",
       "  'prob': [0.2, 0.2, 0.2, 0.2, 0.05, 0.05, 0.05, 0.025, 0.025]},\n",
       " 'ো': {'word': ['ু', 'ী', 'প', 'ল', '[', 'ঊ', 'জ', 'া', 'ি'],\n",
       "  'prob': [0.2, 0.2, 0.2, 0.2, 0.05, 0.05, 0.05, 0.025, 0.025]},\n",
       " 'ৌ': {'word': ['ৈ', 'ও৭', 'ও৮', 'ঐ', 'ওও', 'ওক', 'ওণ', 'া', 'ি'],\n",
       "  'prob': [0.2, 0.2, 0.2, 0.2, 0.05, 0.05, 0.05, 0.025, 0.025]},\n",
       " '্': {'word': ['.', '।', 'ল', 'ক', '/', ';', 'প', 'উ', 'ঊ'],\n",
       "  'prob': [0.2, 0.2, 0.2, 0.2, 0.05, 0.05, 0.05, 0.025, 0.025]},\n",
       " '১': {'word': ['২', 'ক', '৩', 'ও', 'ওঃ', 'ল', 'ম'],\n",
       "  'prob': [0.4, 0.4, 0.05, 0.05, 0.05, 0.025, 0.025]},\n",
       " '২': {'word': ['১', '৩', 'ও', 'ওঃ', '৪', 'া', 'আ', 'ল', 'ম'],\n",
       "  'prob': [0.2, 0.2, 0.2, 0.2, 0.05, 0.05, 0.05, 0.025, 0.025]},\n",
       " '৩': {'word': ['২', '৪', 'এ', 'ে', '১', '৫', 'া', 'ল', 'ম'],\n",
       "  'prob': [0.2, 0.2, 0.2, 0.2, 0.05, 0.05, 0.05, 0.025, 0.025]},\n",
       " '৪': {'word': ['৩', '৫', 'এ', 'ে', '২', '৬', 'ড', 'া', 'আ'],\n",
       "  'prob': [0.2, 0.2, 0.2, 0.2, 0.05, 0.05, 0.05, 0.025, 0.025]},\n",
       " '৫': {'word': ['৬', '৪', 'র', 'ঢ়', '৭', '৩', 'ড', 'া', 'আ'],\n",
       "  'prob': [0.2, 0.2, 0.2, 0.2, 0.05, 0.05, 0.05, 0.025, 0.025]},\n",
       " '৬': {'word': ['৭', '৫', 'ত', 'তঁ', '৮', '৪', 'ফ', 'ড', 'দ'],\n",
       "  'prob': [0.2, 0.2, 0.2, 0.2, 0.05, 0.05, 0.05, 0.025, 0.025]},\n",
       " '৭': {'word': ['৮', '৬', 'ইয়', 'য়', '৯', '৫', 'গ', 'ড', 'দ'],\n",
       "  'prob': [0.2, 0.2, 0.2, 0.2, 0.05, 0.05, 0.05, 0.025, 0.025]},\n",
       " '৮': {'word': ['৭', '৯', 'উ', 'ঊ', '৬', '০', 'ইয়', 'ত', 'তঁ'],\n",
       "  'prob': [0.2, 0.2, 0.2, 0.2, 0.05, 0.05, 0.05, 0.025, 0.025]},\n",
       " '৯': {'word': ['৮', '০', 'ই', 'ঈ', '৭', '-', 'উ', 'ইয়', 'য়'],\n",
       "  'prob': [0.2, 0.2, 0.2, 0.2, 0.05, 0.05, 0.05, 0.025, 0.025]},\n",
       " '০': {'word': ['৯', '-', 'ও', 'ওঃ', '=', '৮', 'ই', 'উ', 'ঊ'],\n",
       "  'prob': [0.2, 0.2, 0.2, 0.2, 0.05, 0.05, 0.05, 0.025, 0.025]}}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_prob_dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f9ab9ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import load_dataset\n",
    "# dataset = load_dataset(\"shahidul034/error_correction_model_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f5f8ad4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=r\"C:\\Users\\Administrator\\Desktop\\my research(Shakib)\\error correction model\\hasan murad bhai data\\Synthetic_Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "66c315f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "list_data=[]\n",
    "li=os.listdir(path)\n",
    "for x in li:\n",
    "    f=open(os.path.join(path,x),\"r\",encoding=\"utf-8\").read().split(\"\\n\")\n",
    "    list_data.extend(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1c42c737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['content'],\n",
      "        num_rows: 19051\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets.dataset_dict import DatasetDict\n",
    "from datasets import Dataset\n",
    "d = {'train':Dataset.from_dict({'content':f})}\n",
    "data=DatasetDict(d)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9b89debd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c64d2f8f2e3a4ad8b5ce47a5e886de7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data=data['train'].filter(lambda x: len(x['content'])>=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "71c4fc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def random_word(word):\n",
    "  elements = char_prob_dis[word]['word']\n",
    "  probabilities = char_prob_dis[word]['prob']\n",
    "  a=np.random.choice(elements, 1, p=probabilities)\n",
    "  return a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9d5d0ee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['content'],\n",
       "    num_rows: 19043\n",
       "})"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9bdb09b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "s=set()\n",
    "for x in data['content']:\n",
    "    if len(x)<=4:\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b99d1832",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 19043/19043 [00:46<00:00, 407.74it/s]\n"
     ]
    }
   ],
   "source": [
    "syn_dataset=[]\n",
    "import tqdm\n",
    "for x in tqdm.tqdm(data):\n",
    "  f=0\n",
    "  for x2 in x['content']:\n",
    "     if x2 in list_char:\n",
    "       f+=1\n",
    "  if f<(len(x['content'])/2):\n",
    "    continue\n",
    "  flag=1\n",
    "  while random.randint(1,6)!=2 or flag:\n",
    "    flag=0\n",
    "    sent=[x2 for x2 in x['content']]\n",
    "    flag2=1\n",
    "    while random.randint(1,3)!=2 or flag2:\n",
    "      flag2=0\n",
    "      pos=random.randint(0,len(sent)-1)\n",
    "      patience=0\n",
    "      ff=1\n",
    "      while sent[pos] not in list_char:\n",
    "        #random position (change the word)\n",
    "        patience+=1\n",
    "        if patience==5:\n",
    "          ff=0\n",
    "          break\n",
    "        pos=random.randint(0,len(sent)-1)\n",
    "     \n",
    "      if ff==1:\n",
    "        ch=random_word(sent[pos])\n",
    "        sent[pos]=ch\n",
    "    if ff==1:\n",
    "      inc=(''.join(sent))\n",
    "      syn_dataset.append({\"incorrect\":inc,\"correct\":x['content']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c6d7df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "381238ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "df = pd.DataFrame.from_records(syn_dataset)\n",
    "dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f4ee7a75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'incorrect': 'ঢাকা, ধানজন্ডি, তল্লাঞাঘ বাই ক্রন',\n",
       "  'correct': 'ঢাকা, ধানমন্ডি, তল্লাবাঘ বাই লেন'},\n",
       " {'incorrect': 'ঢাকা, ধানমন্ড৯, তল্লাবাঘ বাই লেও',\n",
       "  'correct': 'ঢাকা, ধানমন্ডি, তল্লাবাঘ বাই লেন'},\n",
       " {'incorrect': 'ঢাকা, যহানমন.ডি, তঅ্লাবাঘ বাই লেন',\n",
       "  'correct': 'ঢাকা, ধানমন্ডি, তল্লাবাঘ বাই লেন'},\n",
       " {'incorrect': 'দহাকা, ধানমন্ডি, তপ্লাবাঘ বাই কেন',\n",
       "  'correct': 'ঢাকা, ধানমন্ডি, তল্লাবাঘ বাই লেন'},\n",
       " {'incorrect': 'ঢালা, ধাঞএক্সন।ডি, তল্লাবওঘ মওই লেন',\n",
       "  'correct': 'ঢাকা, ধানমন্ডি, তল্লাবাঘ বাই লেন'},\n",
       " {'incorrect': 'দঃাকা, যহানমন্ডি, তল্লাবাঘ বাই লেন',\n",
       "  'correct': 'ঢাকা, ধানমন্ডি, তল্লাবাঘ বাই লেন'},\n",
       " {'incorrect': 'ঢসকা, ধানমন্ডি, তল্লাব্বঘ বাই লেন',\n",
       "  'correct': 'ঢাকা, ধানমন্ডি, তল্লাবাঘ বাই লেন'},\n",
       " {'incorrect': 'ঢাকা যহানমন্ডি তল্লাবাঘ বাই লেন',\n",
       "  'correct': 'ঢাকা ধানমন্ডি তল্লাবাঘ বাই লেন'},\n",
       " {'incorrect': 'ঢাক্য ধানমন্ডি তল্লাবাঘ বসই লেন',\n",
       "  'correct': 'ঢাকা ধানমন্ডি তল্লাবাঘ বাই লেন'},\n",
       " {'incorrect': 'ঢাকা ধাঙমন্ডি তল্লাবাঘ বাক ;েন',\n",
       "  'correct': 'ঢাকা ধানমন্ডি তল্লাবাঘ বাই লেন'}]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn_dataset[400:400+10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "977930f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44fd73d18c9c40d69139a0a9a5e1007a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/12 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "46773060"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.to_json(r\"C:\\Users\\Administrator\\Desktop\\my research(Shakib)\\error correction model\\murad_bhai_data.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3190bf9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.save_to_disk(r\"C:\\Users\\Administrator\\Desktop\\my research(Shakib)\\error correction model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d924d2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login successful\n",
      "Your token has been saved to C:\\Users\\Administrator/.huggingface/token\n",
      "\u001b[1m\u001b[31mAuthenticated through git-credential store but this isn't the helper defined on your machine.\n",
      "You might have to re-authenticate when pushing to the Hugging Face Hub. Run the following command in your terminal in case you want to set this credential helper as the default\n",
      "\n",
      "git config --global credential.helper store\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c8333847",
   "metadata": {},
   "outputs": [],
   "source": [
    "sharding={}\n",
    "total_shard=10\n",
    "for x in range(0,total_shard):\n",
    "  sharding[x]=dataset.shard(num_shards=total_shard,index=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5961c766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['incorrect', 'correct'],\n",
       "    num_rows: 1602893\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sharding[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a932837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "594b4a5c1a814d0191b1750bf8591ba5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\ppg\\lib\\site-packages\\huggingface_hub\\hf_api.py:2165: FutureWarning: `identical_ok` has no effect and is deprecated. It will be removed in 0.11.0.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "sharding[0].push_to_hub(\"shahidul034/error_correction_dataset1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a24a8ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
